---
title: 'Extra: K-Means Clustering'
author: Luca Baggi
date: '2021-01-14'
slug: []
categories: []
tags: []
ShowToc: true
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>Finally, we want to see how many clusters of data can be found by analysing patterns: perhaps the model will catch flows between neighbourhoods or cluster data by date.</p>
<div id="load-packages" class="section level1">
<h1>Load Packages</h1>
<pre class="r"><code># for manipulating data
library(tidyverse)

# for plotting dendograms
library(dendextend)

# for kmeans
library(factoextra)
library(NbClust)</code></pre>
</div>
<div id="load-data" class="section level1">
<h1>Load Data</h1>
<p>Load the data for one last time:</p>
<pre class="r"><code>trips &lt;-
  read_csv(
    &#39;https://raw.githubusercontent.com/baggiponte/escooters-louisville-r/main/data/escooters_od_reduced.csv&#39;,
    col_types = cols(
      StartTime = col_datetime(format = &#39;%Y-%m-%dT%H:%M:%SZ&#39;),
      Covid = col_factor(),
      StartNH = col_factor(),
      EndNH = col_factor()
    )) %&gt;%
  slice_sample(prop = 0.1) %&gt;%
  as_tibble()</code></pre>
</div>
<div id="standardise-the-data" class="section level1">
<h1>Standardise the Data</h1>
<p>We need standardised data to have comparable variables, then compute the distances:</p>
<pre class="r"><code>distance &lt;- trips %&gt;%
  mutate(across(where(is.factor), as.numeric)) %&gt;%
  mutate(StartTime = as.numeric(StartTime)) %&gt;%
  scale() %&gt;%
  dist(method = &#39;euclidean&#39;)</code></pre>
</div>
<div id="compare-different-hierarchical-clustering-distances" class="section level1">
<h1>Compare Different Hierarchical Clustering Distances</h1>
<div id="complete-linkage" class="section level2">
<h2>Complete Linkage</h2>
<p>Let’s start with the <code>complete</code> linkage:</p>
<pre class="r"><code>set.seed(42)

# compute the clusters
hclust_complete &lt;- hclust(distance, method = &#39;complete&#39;)

# and plot them
plot(hclust_complete, labels = F)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code># cut at the expected height of the number of our NH
cut_complete &lt;- hclust_complete %&gt;%
  cutree(6)</code></pre>
<p>And we create a table with the combinations. Let’s use a custom function:</p>
<pre class="r"><code>clust_table &lt;- function(cut, col1) {
  
  tibble(cut = cut, col1 = trips[[col1]]) %&gt;%
  mutate(cut = as.factor(cut)) %&gt;%
  group_by(col1) %&gt;%
  count(cut) %&gt;%
  pivot_wider(names_from = col1, values_from = n)
}</code></pre>
<p>And then create the two tables:</p>
<pre class="r"><code>clust_table(cut_complete, &#39;StartNH&#39;)</code></pre>
<pre><code>## # A tibble: 6 x 7
##   cut   Downtown `Northeast Core` University `West Core` `Southeast Core` Other
##   &lt;fct&gt;    &lt;int&gt;            &lt;int&gt;      &lt;int&gt;       &lt;int&gt;            &lt;int&gt; &lt;int&gt;
## 1 1         1727               51       1083         164              133    16
## 2 2          130               73         32           5               19    24
## 3 4           66               29         13           8               45    10
## 4 5           NA               NA         NA          10               NA    43
## 5 3           NA               NA         NA          NA              167     7
## 6 6           NA               NA         NA          NA               NA     2</code></pre>
<pre class="r"><code>clust_table(cut_complete, &#39;EndNH&#39;)</code></pre>
<pre><code>## # A tibble: 6 x 7
##   cut   Downtown `Southeast Core` University `West Core` `Northeast Core` Other
##   &lt;fct&gt;    &lt;int&gt;            &lt;int&gt;      &lt;int&gt;       &lt;int&gt;            &lt;int&gt; &lt;int&gt;
## 1 1         1761              184       1073         154                2    NA
## 2 3            6              151          1          NA                3    13
## 3 4           59               43         21           4               28    16
## 4 5            2                1          9           9               NA    32
## 5 2           NA               NA         NA          12              158   113
## 6 6           NA               NA         NA          NA               NA     2</code></pre>
</div>
<div id="single-linkage" class="section level2">
<h2>Single Linkage</h2>
<p>And let’s compare it with the <code>single</code> distance:</p>
<pre class="r"><code>set.seed(42)
# compute the clusters
hclust_single &lt;- hclust(distance, method = &#39;single&#39;)

# and plot them
plot(hclust_single, labels = F)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code># cut at the expected height of the number of our NH
cut_single &lt;- hclust_single %&gt;%
  cutree(6)</code></pre>
<p>And see the correspondences:</p>
<pre class="r"><code>clust_table(cut_single, &#39;StartNH&#39;)</code></pre>
<pre><code>## # A tibble: 6 x 7
##   cut   Downtown `Northeast Core` University `West Core` `Southeast Core` Other
##   &lt;fct&gt;    &lt;int&gt;            &lt;int&gt;      &lt;int&gt;       &lt;int&gt;            &lt;int&gt; &lt;int&gt;
## 1 1         1857              124       1115         179              319    89
## 2 2           66               29         13           8               39     5
## 3 3           NA               NA         NA          NA                6     5
## 4 4           NA               NA         NA          NA               NA     1
## 5 5           NA               NA         NA          NA               NA     1
## 6 6           NA               NA         NA          NA               NA     1</code></pre>
<pre class="r"><code>clust_table(cut_single, &#39;EndNH&#39;)</code></pre>
<pre><code>## # A tibble: 6 x 7
##   cut   Downtown `Southeast Core` University `West Core` `Northeast Core` Other
##   &lt;fct&gt;    &lt;int&gt;            &lt;int&gt;      &lt;int&gt;       &lt;int&gt;            &lt;int&gt; &lt;int&gt;
## 1 1         1768              336       1083         175              163   158
## 2 2           59               43         21           4               26     7
## 3 4            1               NA         NA          NA               NA    NA
## 4 3           NA               NA         NA          NA                2     9
## 5 5           NA               NA         NA          NA               NA     1
## 6 6           NA               NA         NA          NA               NA     1</code></pre>
<p>It is no better! Clusters are assigned in the same way, except until <code>Southeast Core</code>.</p>
</div>
</div>
<div id="plot-prettier-dendograms" class="section level1">
<h1>Plot Prettier Dendograms</h1>
<pre class="r"><code>as.dendrogram(hclust_complete) %&gt;%
  color_branches(h = 6) %&gt;%
  plot()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>as.dendrogram(hclust_single) %&gt;%
  color_branches(h = 6) %&gt;%
  plot()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
<p>This is the problem with single linkage! Clusters are too spread out and not close enough.</p>
</div>
<div id="mapping" class="section level1">
<h1>Mapping</h1>
<p>Finally, we can plot the points with <code>ggplot</code>:</p>
<pre class="r"><code>trips %&gt;%
  bind_cols(cut_complete) %&gt;%
  ggplot(aes(x = StartLongitude, y = StartLatitude, col = factor(cut_complete))) + 
  geom_point() +
  labs(x = &#39;Start Longitude&#39;,
       y = &#39;Start Latitude&#39;,
       col = &#39;Cluster&#39;,
       title = &#39;Complete Linkage&#39;)</code></pre>
<pre><code>## New names:
## * NA -&gt; ...7</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>trips %&gt;%
  bind_cols(cut_single) %&gt;%
  ggplot(aes(x = StartLongitude, y = StartLatitude, col = factor(cut_single))) + 
  geom_point() +
  labs(x = &#39;Start Longitude&#39;,
       y = &#39;Start Latitude&#39;,
       col = &#39;Cluster&#39;,
       title = &#39;Single Linkage&#39;)</code></pre>
<pre><code>## New names:
## * NA -&gt; ...7</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-10-2.png" width="672" /></p>
</div>
<div id="k-means-clustering" class="section level1">
<h1>K-Means Clustering</h1>
<pre class="r"><code>set.seed(42)

trips %&gt;%
  mutate(across(where(is.factor), as.numeric)) %&gt;%
  mutate(StartTime = as.numeric(StartTime)) %&gt;%
  scale() -&gt; df

df %&gt;%
  fviz_nbclust(
    kmeans,
    method = &#39;wss&#39;,
    k.max = 20,
    # number of MC resamples
    nboot = 200
  ) +
  labs(subtitle = &#39;wss&#39;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>There are at least 6 clusters, which corresponds to the actual number of neighbourhoods! Another equivalent way of doing it is with <code>NbClust</code>:</p>
<pre class="r"><code>set.seed(42)

nb_clusters_gap &lt;- df %&gt;%
  NbClust(distance = &#39;euclidean&#39;,
          min.nc = 2,
          max.nc = 20,
          method = &#39;kmeans&#39;,
          index = &#39;gap&#39;)

nb_clusters_gap$Best.nc</code></pre>
<pre><code>## Number_clusters     Value_Index 
##           2.000           0.355</code></pre>
<pre class="r"><code>nb_clusters_ch &lt;- df %&gt;%
  NbClust(distance = &#39;euclidean&#39;,
          min.nc = 2,
          max.nc = 20,
          method = &#39;kmeans&#39;,
          # Calinski &amp; Harabasz criterion
          index = &#39;ch&#39;)

nb_clusters_ch$Best.nc</code></pre>
<pre><code>## Number_clusters     Value_Index 
##           4.000        2172.858</code></pre>
<p>However, different indexes give indications for different cluster numbers! <code>ch</code> maximises the ratio of the between cluster variation and within cluster variation. <code>gap</code> gives a measure of how much <code>wss</code> drops with each cluster.</p>
</div>
